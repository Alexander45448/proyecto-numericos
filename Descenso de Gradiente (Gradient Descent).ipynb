{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1507fcac",
   "metadata": {},
   "source": [
    "# *Tema: Descenso de Gradiente (Gradient Descent).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda64fa",
   "metadata": {},
   "source": [
    "## *Grupo $\\beta$* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb6e1ec",
   "metadata": {},
   "source": [
    "### *Integrantes:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a503ba76",
   "metadata": {},
   "source": [
    "*1.Carmen Elisa Lopez Alvarado 00100619*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321051e",
   "metadata": {},
   "source": [
    "*2.Rodrigo Antonio Ungo Muñoz 00075419*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f794120",
   "metadata": {},
   "source": [
    "*3.Dennys Alberto Rivera Pascasio 00026919*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef1a01",
   "metadata": {},
   "source": [
    "*4.Alexander Ernesto Menéndez Navarrete 00098818*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d6391",
   "metadata": {},
   "source": [
    "## *1. Definicion*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d050527",
   "metadata": {},
   "source": [
    "El descenso de gradiente es un algoritmo de uso general que numéricamente encuentra un mínimo de funciones multivariables, donde una función genera sus valores más bajos. Eso significa que encuentra mínimos locales, pero no al establecer $\\nabla$$f$=0. En lugar de encontrar mínimos manipulando símbolos, el descenso de gradiente aproxima la solución con números."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa5ca20",
   "metadata": {},
   "source": [
    "<img src=\"Downloads/graf.jpeg\" width=400 height=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140673eb",
   "metadata": {},
   "source": [
    "## *2. Convergencia del Descenso de Gradiente (Gradient Descent)*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04289f58",
   "metadata": {},
   "source": [
    "Gradient Descent es un algoritmo diseñado para encontrar puntos óptimos, pero estos puntos óptimos no son necesariamente globales. Y si sucede que diverge de una ubicación local, puede converger a otro punto óptimo, pero su probabilidad no es demasiada. La razón es que el tamaño del paso puede ser demasiado grande, lo que hace que retroceda un punto óptimo y la probabilidad de que oscile es mucho más que convergencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e7670d",
   "metadata": {},
   "source": [
    "Sobre el descenso por gradiente hay dos perspectivas principales, la era del aprendizaje automático y la era del aprendizaje profundo. Durante la era de aprendizaje automático, se consideró que el descenso de gradiente encontrará el óptimo local / global, pero en la era de aprendizaje profundo, donde la dimensión de las características de entrada es demasiado, en la práctica se muestra que la probabilidad de que todas las características estén ubicadas en su valor óptimo en un solo punto no es demasiado y, más bien, ver que hay ubicaciones óptimas en las funciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae09f3ce",
   "metadata": {},
   "source": [
    "Además de los puntos mencionados (convergencia a mínimos no globales y pasos de gran tamaño que posiblemente conduzcan a algoritmos no convergentes), los \"puntos de inflexión\" (puntos en una curva que cambia el signo de la curvatura) también podrían ser un problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab31824",
   "metadata": {},
   "source": [
    "Considere el siguiente tipo de función de \"silla de montar\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06a7e5c",
   "metadata": {},
   "source": [
    "<img src=\"Downloads/silla.jpg\" width=300 height=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fc8b3b",
   "metadata": {},
   "source": [
    "Obviamente, esto se puede construir de modo que haya un rango en el medio donde el gradiente sea el vector 0. En este rango, el algoritmo se puede atascar indefinidamente. Los puntos de inflexión generalmente no se consideran extremos locales, sino que pueden ser puntos estacionarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2596b9c",
   "metadata": {},
   "source": [
    "## *3. Ventajas del Descenso de Gradiente*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412d6df",
   "metadata": {},
   "source": [
    "• Es más efectivo para minimizar funciones complejas y multidimensionales que el método de derivadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a58d00",
   "metadata": {},
   "source": [
    "• Sin importar la cantidad de variables, el descanso de gradiente proveerá un valor aproximado del punto mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca34f7",
   "metadata": {},
   "source": [
    "• El uso de la primera derivada en el método evita ambigüedad con respecto a qué dirección el algoritmo converge. Esto es especialmente útil en funciones tridimensionales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fcd42d",
   "metadata": {},
   "source": [
    "## *4. Desventajas del Descenso de Gradiente*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9faacbe",
   "metadata": {},
   "source": [
    "• Este método no garantiza que el mínimo encontrado es el mínimo global de la función."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e0b5b9",
   "metadata": {},
   "source": [
    "• Se requiere de información local para realizar el cálculo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5455ccf2",
   "metadata": {},
   "source": [
    "• Si el salto α es muy grande podría no converger al mínimo que se desea buscar debido a que se excedería con cada paso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003dc124",
   "metadata": {},
   "source": [
    "• Por el contrario, si el salto α es muy pequeño, se aumenta la probabilidad de convergencia, pero cuando la función posee muchas variables, la convergencia se vuelve lenta. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf6bb65",
   "metadata": {},
   "source": [
    "• El descenso de gradiente solo funciona cuando la función es diferenciable en todas partes. Si la función es segmentada la convergencia será imposible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03374c53",
   "metadata": {},
   "source": [
    "## *5. Ejemplo matematico y computacional*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d466a0",
   "metadata": {},
   "source": [
    "Cuando tenemos una función $f$ multivariable, el gradiente se obtiene al derivar parcialmente la función $f$ con respecto a cada variable independiente, y se denota con el símbolo Nabla $\\nabla $. Con el descenso de gradiente, nos enfocamos más en la dirección de la disminución más rápida de la función, la cual se determina por medio de  -$\\nabla$$f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88935890",
   "metadata": {},
   "source": [
    "La lógica del descenso de gradiente es comenzar desde un punto arbitrario y avanzar (descender) paulatinamente hasta llegar a un mínimo, y se calcula mediante $x_{n+1} = x_{n}-\\eta \\nabla f(x_{n})$, donde $\\eta$ es un valor positivo llamado Tasa de aprendizaje, o también conocido como Tamaño de paso. La Tasa de aprendizaje es importante en este algoritmo, puesto que, si $\\eta$ es demasiado pequeño, el algoritmo convergerá a costa de un mayor tiempo de convergencia, pero si es más grande de lo necesario, el algoritmo puede tener diferentes resultados, como converger lentamente o divergir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8dd997",
   "metadata": {},
   "source": [
    "Vamos a calcular el gradiente de una función $C$ de varias variables independientes $v_{1}...,v_{r}$ se denota con $\\eta \\nabla$ y se define como la función vectorial de las derivadas parciales de $C$ con respecto a cada variable independiente.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bbc5f0",
   "metadata": {},
   "source": [
    "Realizaremos un ejemplo y sera encontrar el minimo de la funcion $C = v^2$, lo haremos mediente un programa el cual encontrar el minimo de la funcion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334affc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5411474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "gradient: función para el gradiente\n",
    "strart: comienza la busqueda \n",
    "learn_rate: la taza de aprendizaje\n",
    "n_iter: número de iteraciones\n",
    "tolerance: tolerancia o precisión deseada\n",
    "'''\n",
    "\n",
    "def gradient_descent(\n",
    "    gradient, start, learn_rate, n_iter=50, tolerance=1e-06\n",
    "):\n",
    "    vector = start\n",
    "    for _ in range(n_iter):\n",
    "        diff = -learn_rate * gradient(vector)\n",
    "        if np.all(np.abs(diff) <= tolerance):\n",
    "            break\n",
    "        vector += diff\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5243a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.210739197207331e-06"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(\n",
    "...     gradient=lambda v: 2 * v, start=10.0, learn_rate=0.2\n",
    "... )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d0e371",
   "metadata": {},
   "source": [
    "## *5.1 Grafica del ejercicio*\n",
    "\n",
    "<img src=\"Downloads/grafica.jpeg\" width=600 height=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2d6d77",
   "metadata": {},
   "source": [
    "## *6. Referencias Bibliograficas*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34498f31",
   "metadata": {},
   "source": [
    "1. Academy, K. (2017, 14 abril). Descenso de gradiente. Khan Academy. https://es.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/optimizing-multivariable-functions/a/what-is-gradient-descent#:~:text=El%20descenso%20de%20gradiente%20es%20un%20algoritmo%20que%20estima%20num%C3%A9ricamente,genera%20sus%20valores%20m%C3%A1s%20bajos.&text=En%20lugar%20de%20encontrar%20m%C3%ADnimos,aproxima%20la%20soluci%C3%B3n%20con%20n%C3%BAmeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cecb19",
   "metadata": {},
   "source": [
    "2. ¿El descenso del gradiente siempre converge a un óptimo? (s. f.). Qastack. Recuperado 19 de junio de 2021, de https://qastack.mx/datascience/24534/does-gradient-descent-always-converge-to-an-optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf0a7e6",
   "metadata": {},
   "source": [
    "3. Khan Academy. (2019). Descenso de gradiente (artículo) - Khan Academy. https://es.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/optimizing-multivariable-functions/a/what-is-gradient-descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656be2c",
   "metadata": {},
   "source": [
    "4. Ruiz, I. V. M. (2016, 21 noviembre). Descenso por gradiente (Gradient descent). Ivan Vladimir Meza Ruiz. https://turing.iimas.unam.mx/%7Eivanvladimir/posts/gradient_descent/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6769b5cc",
   "metadata": {},
   "source": [
    "5. Stojiljković, M. (2021, 27 enero). Algoritmo de descenso de gradiente estocástico con Python y NumPy. Real Python. https://realpython.com/gradient-descent-algorithm-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f368631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
